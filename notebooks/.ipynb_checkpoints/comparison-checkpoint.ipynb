{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T07:40:08.447923Z",
     "start_time": "2025-10-27T07:38:28.136177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.lexicon_absa import LexiconABSA\n",
    "from src.transformer_absa import TransformerABSA\n",
    "from src.llm_absa import LLMABSA\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ASPECT-BASED SENTIMENT ANALYSIS - THREE APPROACHES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test samples\n",
    "test_texts = [\n",
    "    \"The pizza was delicious but the service was terrible.\",\n",
    "    \"Great battery life but the camera quality is disappointing.\",\n",
    "    \"The hotel room was clean and spacious, but the wifi was slow.\",\n",
    "]\n",
    "\n",
    "# Initialize all analyzers\n",
    "analyzers = {\n",
    "    'Lexicon': LexiconABSA(),\n",
    "    'Transformer': TransformerABSA(),\n",
    "    'LLM': LLMABSA()\n",
    "}\n",
    "\n",
    "# Compare results\n",
    "for text in test_texts:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Text: {text}\")\n",
    "    print('='*60)\n",
    "\n",
    "    for name, analyzer in analyzers.items():\n",
    "        print(f\"\\n{name} Results:\")\n",
    "        start = time.time()\n",
    "        results = analyzer.analyze(text)\n",
    "        elapsed = time.time() - start\n",
    "\n",
    "        for r in results:\n",
    "            print(f\"  {r}\")\n",
    "        print(f\"  Time: {elapsed:.3f}s\")\n",
    "\n",
    "\n",
    "summary_data = []\n",
    "for text in test_texts:\n",
    "    row = {'text': text[:50] + '...'}\n",
    "    for name, analyzer in analyzers.items():\n",
    "        start = time.time()\n",
    "        results = analyzer.analyze(text)\n",
    "        row[f'{name}_aspects'] = len(results)\n",
    "        row[f'{name}_time'] = f\"{time.time() - start:.3f}s\"\n",
    "    summary_data.append(row)\n",
    "    print(\"\\n SUMMARY TABLE\\n\")\n",
    "    print(pd.DataFrame(summary_data).to_string(index=False))\n",
    "\n",
    "pd.DataFrame(summary_data)\n",
    "\n",
    "# === PERFORMANCE METRICS ===\n",
    "print(\"\\nðŸ“Š PERFORMANCE COMPARISON\\n\")\n",
    "\n",
    "# Extract timing data\n",
    "timing_data = {name: [] for name in analyzers.keys()}\n",
    "for text in test_texts:\n",
    "    for name, analyzer in analyzers.items():\n",
    "        start = time.time()\n",
    "        _ = analyzer.analyze(text)\n",
    "        timing_data[name].append(time.time() - start)\n",
    "\n",
    "# Plot 1: Timing comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart - average time\n",
    "avg_times = {name: np.mean(times) for name, times in timing_data.items()}\n",
    "axes[0].bar(avg_times.keys(), avg_times.values(), color=['#2ecc71', '#3498db', '#e74c3c'])\n",
    "axes[0].set_ylabel('Time (seconds)', fontsize=12)\n",
    "axes[0].set_title('Average Execution Time', fontsize=14, fontweight='bold')\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "# Plot 2: Aspects detected\n",
    "aspect_counts = {name: [] for name in analyzers.keys()}\n",
    "for text in test_texts:\n",
    "    for name, analyzer in analyzers.items():\n",
    "        results = analyzer.analyze(text)\n",
    "        aspect_counts[name].append(len(results))\n",
    "\n",
    "x = np.arange(len(test_texts))\n",
    "width = 0.25\n",
    "for i, (name, counts) in enumerate(aspect_counts.items()):\n",
    "    axes[1].bar(x + i*width, counts, width, label=name)\n",
    "axes[1].set_xlabel('Test Texts', fontsize=12)\n",
    "axes[1].set_ylabel('Aspects Detected', fontsize=12)\n",
    "axes[1].set_title('Aspect Detection by Method', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xticks(x + width)\n",
    "axes[1].set_xticklabels(['Text 1', 'Text 2', 'Text 3'])\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === QUALITATIVE ANALYSIS ===\n",
    "print(\"\\nðŸ” DETAILED COMPARISON - TEXT 1\\n\")\n",
    "text = test_texts[0]\n",
    "print(f\"Text: '{text}'\\n\")\n",
    "\n",
    "comparison_results = []\n",
    "for name, analyzer in analyzers.items():\n",
    "    results = analyzer.analyze(text)\n",
    "    for r in results:\n",
    "        comparison_results.append({\n",
    "            'Method': name,\n",
    "            'Aspect': r.aspect,\n",
    "            'Sentiment': r.sentiment,\n",
    "            'Confidence': f\"{r.confidence:.2f}\"\n",
    "        })\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_results)\n",
    "print(df_comparison.to_string(index=False))\n",
    "\n",
    "print(\"\\nâš ï¸ EDGE CASES\\n\")\n",
    "for text, label in [(\"wasn't bad\", \"Negation\"), (\"okay\", \"Neutral\")]:\n",
    "    print(f\"{label}: '{text}'\")\n",
    "    for name, analyzer in analyzers.items():\n",
    "        r = analyzer.analyze(text)\n",
    "        print(f\"  {name}: {len(r)} aspects\")\n",
    "\n",
    "print(\"\\n RECOMMENDATIONS:\")\n",
    "print(\"Real-time API â†’ Lexicon | Production â†’ Transformer | Research â†’ LLM\")"
   ],
   "id": "438d7d13be19ca8a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Text: The pizza was delicious but the service was terrible.\n",
      "============================================================\n",
      "\n",
      "Lexicon Results:\n",
      "  Aspect: 'The pizza' â†’ Sentiment: POSITIVE (confidence: 0.57)\n",
      "  Aspect: 'the service' â†’ Sentiment: NEGATIVE (confidence: 0.48)\n",
      "  Time: 0.058s\n",
      "\n",
      "Transformer Results:\n",
      "  Aspect: 'The pizza' â†’ Sentiment: POSITIVE (confidence: 1.00)\n",
      "  Aspect: 'the service' â†’ Sentiment: NEGATIVE (confidence: 0.99)\n",
      "  Time: 0.871s\n",
      "\n",
      "LLM Results:\n",
      "  Aspect: 'pizza' â†’ Sentiment: POSITIVE (confidence: 0.95)\n",
      "  Aspect: 'service' â†’ Sentiment: NEGATIVE (confidence: 0.85)\n",
      "  Time: 52.997s\n",
      "\n",
      "============================================================\n",
      "Text: Great battery life but the camera quality is disappointing.\n",
      "============================================================\n",
      "\n",
      "Lexicon Results:\n",
      "  Aspect: 'Great battery life' â†’ Sentiment: POSITIVE (confidence: 0.23)\n",
      "  Aspect: 'the camera quality' â†’ Sentiment: NEGATIVE (confidence: 0.65)\n",
      "  Time: 0.007s\n",
      "\n",
      "Transformer Results:\n",
      "  Aspect: 'Great battery life' â†’ Sentiment: POSITIVE (confidence: 1.00)\n",
      "  Aspect: 'the camera quality' â†’ Sentiment: NEGATIVE (confidence: 1.00)\n",
      "  Time: 0.306s\n",
      "\n",
      "LLM Results:\n",
      "  Aspect: 'battery life' â†’ Sentiment: POSITIVE (confidence: 0.90)\n",
      "  Aspect: 'camera quality' â†’ Sentiment: NEGATIVE (confidence: 0.80)\n",
      "  Time: 20.861s\n",
      "\n",
      "============================================================\n",
      "Text: The hotel room was clean and spacious, but the wifi was slow.\n",
      "============================================================\n",
      "\n",
      "Lexicon Results:\n",
      "  Aspect: 'The hotel room' â†’ Sentiment: POSITIVE (confidence: 0.40)\n",
      "  Aspect: 'the wifi' â†’ Sentiment: NEUTRAL (confidence: 0.00)\n",
      "  Time: 0.008s\n",
      "\n",
      "Transformer Results:\n",
      "  Aspect: 'The hotel room' â†’ Sentiment: POSITIVE (confidence: 1.00)\n",
      "  Aspect: 'the wifi' â†’ Sentiment: NEGATIVE (confidence: 1.00)\n",
      "  Time: 0.289s\n",
      "\n",
      "LLM Results:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 30\u001B[39m\n\u001B[32m     28\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m Results:\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     29\u001B[39m start = time.time()\n\u001B[32m---> \u001B[39m\u001B[32m30\u001B[39m results = \u001B[43manalyzer\u001B[49m\u001B[43m.\u001B[49m\u001B[43manalyze\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     31\u001B[39m elapsed = time.time() - start\n\u001B[32m     33\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m r \u001B[38;5;129;01min\u001B[39;00m results:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/src/llm_absa.py:15\u001B[39m, in \u001B[36mLLMABSA.analyze\u001B[39m\u001B[34m(self, text)\u001B[39m\n\u001B[32m     12\u001B[39m prompt = \u001B[38;5;28mself\u001B[39m._create_prompt(text)\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m     response = \u001B[43mollama\u001B[49m\u001B[43m.\u001B[49m\u001B[43mchat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     16\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     17\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mrole\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43muser\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mcontent\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m}\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     18\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mjson\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Request JSON output\u001B[39;49;00m\n\u001B[32m     19\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     21\u001B[39m     result = json.loads(response[\u001B[33m'\u001B[39m\u001B[33mmessage\u001B[39m\u001B[33m'\u001B[39m][\u001B[33m'\u001B[39m\u001B[33mcontent\u001B[39m\u001B[33m'\u001B[39m])\n\u001B[32m     22\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._parse_response(result)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/ollama/_client.py:351\u001B[39m, in \u001B[36mClient.chat\u001B[39m\u001B[34m(self, model, messages, tools, stream, think, format, options, keep_alive)\u001B[39m\n\u001B[32m    306\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mchat\u001B[39m(\n\u001B[32m    307\u001B[39m   \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    308\u001B[39m   model: \u001B[38;5;28mstr\u001B[39m = \u001B[33m'\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    316\u001B[39m   keep_alive: Optional[Union[\u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28mstr\u001B[39m]] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    317\u001B[39m ) -> Union[ChatResponse, Iterator[ChatResponse]]:\n\u001B[32m    318\u001B[39m \u001B[38;5;250m  \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    319\u001B[39m \u001B[33;03m  Create a chat response using the requested model.\u001B[39;00m\n\u001B[32m    320\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    349\u001B[39m \u001B[33;03m  Returns `ChatResponse` if `stream` is `False`, otherwise returns a `ChatResponse` generator.\u001B[39;00m\n\u001B[32m    350\u001B[39m \u001B[33;03m  \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m351\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    352\u001B[39m \u001B[43m    \u001B[49m\u001B[43mChatResponse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    353\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mPOST\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    354\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43m/api/chat\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[43m    \u001B[49m\u001B[43mjson\u001B[49m\u001B[43m=\u001B[49m\u001B[43mChatRequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    356\u001B[39m \u001B[43m      \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    357\u001B[39m \u001B[43m      \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m_copy_messages\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    358\u001B[39m \u001B[43m      \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m_copy_tools\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtools\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    359\u001B[39m \u001B[43m      \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    360\u001B[39m \u001B[43m      \u001B[49m\u001B[43mthink\u001B[49m\u001B[43m=\u001B[49m\u001B[43mthink\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    361\u001B[39m \u001B[43m      \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    362\u001B[39m \u001B[43m      \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    363\u001B[39m \u001B[43m      \u001B[49m\u001B[43mkeep_alive\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkeep_alive\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    364\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmodel_dump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexclude_none\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    365\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    366\u001B[39m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/ollama/_client.py:189\u001B[39m, in \u001B[36mClient._request\u001B[39m\u001B[34m(self, cls, stream, *args, **kwargs)\u001B[39m\n\u001B[32m    185\u001B[39m         \u001B[38;5;28;01myield\u001B[39;00m \u001B[38;5;28mcls\u001B[39m(**part)\n\u001B[32m    187\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m inner()\n\u001B[32m--> \u001B[39m\u001B[32m189\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m(**\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_request_raw\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m.json())\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/ollama/_client.py:129\u001B[39m, in \u001B[36mClient._request_raw\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    127\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_request_raw\u001B[39m(\u001B[38;5;28mself\u001B[39m, *args, **kwargs):\n\u001B[32m    128\u001B[39m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m129\u001B[39m     r = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_client\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    130\u001B[39m     r.raise_for_status()\n\u001B[32m    131\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m r\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/httpx/_client.py:825\u001B[39m, in \u001B[36mClient.request\u001B[39m\u001B[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001B[39m\n\u001B[32m    810\u001B[39m     warnings.warn(message, \u001B[38;5;167;01mDeprecationWarning\u001B[39;00m, stacklevel=\u001B[32m2\u001B[39m)\n\u001B[32m    812\u001B[39m request = \u001B[38;5;28mself\u001B[39m.build_request(\n\u001B[32m    813\u001B[39m     method=method,\n\u001B[32m    814\u001B[39m     url=url,\n\u001B[32m   (...)\u001B[39m\u001B[32m    823\u001B[39m     extensions=extensions,\n\u001B[32m    824\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m825\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mauth\u001B[49m\u001B[43m=\u001B[49m\u001B[43mauth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/httpx/_client.py:914\u001B[39m, in \u001B[36mClient.send\u001B[39m\u001B[34m(self, request, stream, auth, follow_redirects)\u001B[39m\n\u001B[32m    910\u001B[39m \u001B[38;5;28mself\u001B[39m._set_timeout(request)\n\u001B[32m    912\u001B[39m auth = \u001B[38;5;28mself\u001B[39m._build_request_auth(request, auth)\n\u001B[32m--> \u001B[39m\u001B[32m914\u001B[39m response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_send_handling_auth\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    915\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    916\u001B[39m \u001B[43m    \u001B[49m\u001B[43mauth\u001B[49m\u001B[43m=\u001B[49m\u001B[43mauth\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    917\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    918\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhistory\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    919\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    920\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    921\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m stream:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/httpx/_client.py:942\u001B[39m, in \u001B[36mClient._send_handling_auth\u001B[39m\u001B[34m(self, request, auth, follow_redirects, history)\u001B[39m\n\u001B[32m    939\u001B[39m request = \u001B[38;5;28mnext\u001B[39m(auth_flow)\n\u001B[32m    941\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m942\u001B[39m     response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_send_handling_redirects\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    943\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    944\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    945\u001B[39m \u001B[43m        \u001B[49m\u001B[43mhistory\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhistory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    946\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    947\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    948\u001B[39m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/httpx/_client.py:979\u001B[39m, in \u001B[36mClient._send_handling_redirects\u001B[39m\u001B[34m(self, request, follow_redirects, history)\u001B[39m\n\u001B[32m    976\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._event_hooks[\u001B[33m\"\u001B[39m\u001B[33mrequest\u001B[39m\u001B[33m\"\u001B[39m]:\n\u001B[32m    977\u001B[39m     hook(request)\n\u001B[32m--> \u001B[39m\u001B[32m979\u001B[39m response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_send_single_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    980\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    981\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._event_hooks[\u001B[33m\"\u001B[39m\u001B[33mresponse\u001B[39m\u001B[33m\"\u001B[39m]:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/httpx/_client.py:1014\u001B[39m, in \u001B[36mClient._send_single_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m   1009\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[32m   1010\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mAttempted to send an async request with a sync Client instance.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1011\u001B[39m     )\n\u001B[32m   1013\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request=request):\n\u001B[32m-> \u001B[39m\u001B[32m1014\u001B[39m     response = \u001B[43mtransport\u001B[49m\u001B[43m.\u001B[49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1016\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response.stream, SyncByteStream)\n\u001B[32m   1018\u001B[39m response.request = request\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:250\u001B[39m, in \u001B[36mHTTPTransport.handle_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    237\u001B[39m req = httpcore.Request(\n\u001B[32m    238\u001B[39m     method=request.method,\n\u001B[32m    239\u001B[39m     url=httpcore.URL(\n\u001B[32m   (...)\u001B[39m\u001B[32m    247\u001B[39m     extensions=request.extensions,\n\u001B[32m    248\u001B[39m )\n\u001B[32m    249\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m map_httpcore_exceptions():\n\u001B[32m--> \u001B[39m\u001B[32m250\u001B[39m     resp = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_pool\u001B[49m\u001B[43m.\u001B[49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    252\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(resp.stream, typing.Iterable)\n\u001B[32m    254\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m Response(\n\u001B[32m    255\u001B[39m     status_code=resp.status,\n\u001B[32m    256\u001B[39m     headers=resp.headers,\n\u001B[32m    257\u001B[39m     stream=ResponseStream(resp.stream),\n\u001B[32m    258\u001B[39m     extensions=resp.extensions,\n\u001B[32m    259\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001B[39m, in \u001B[36mConnectionPool.handle_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    253\u001B[39m         closing = \u001B[38;5;28mself\u001B[39m._assign_requests_to_connections()\n\u001B[32m    255\u001B[39m     \u001B[38;5;28mself\u001B[39m._close_connections(closing)\n\u001B[32m--> \u001B[39m\u001B[32m256\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m exc \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    258\u001B[39m \u001B[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001B[39;00m\n\u001B[32m    259\u001B[39m \u001B[38;5;66;03m# the point at which the response is closed.\u001B[39;00m\n\u001B[32m    260\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response.stream, typing.Iterable)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001B[39m, in \u001B[36mConnectionPool.handle_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    232\u001B[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001B[32m    234\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    235\u001B[39m     \u001B[38;5;66;03m# Send the request on the assigned connection.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m236\u001B[39m     response = \u001B[43mconnection\u001B[49m\u001B[43m.\u001B[49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    237\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpool_request\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrequest\u001B[49m\n\u001B[32m    238\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    239\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m ConnectionNotAvailable:\n\u001B[32m    240\u001B[39m     \u001B[38;5;66;03m# In some cases a connection may initially be available to\u001B[39;00m\n\u001B[32m    241\u001B[39m     \u001B[38;5;66;03m# handle a request, but then become unavailable.\u001B[39;00m\n\u001B[32m    242\u001B[39m     \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[32m    243\u001B[39m     \u001B[38;5;66;03m# In this case we clear the connection and try again.\u001B[39;00m\n\u001B[32m    244\u001B[39m     pool_request.clear_connection()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:103\u001B[39m, in \u001B[36mHTTPConnection.handle_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    100\u001B[39m     \u001B[38;5;28mself\u001B[39m._connect_failed = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m    101\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m exc\n\u001B[32m--> \u001B[39m\u001B[32m103\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_connection\u001B[49m\u001B[43m.\u001B[49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:136\u001B[39m, in \u001B[36mHTTP11Connection.handle_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    134\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m Trace(\u001B[33m\"\u001B[39m\u001B[33mresponse_closed\u001B[39m\u001B[33m\"\u001B[39m, logger, request) \u001B[38;5;28;01mas\u001B[39;00m trace:\n\u001B[32m    135\u001B[39m         \u001B[38;5;28mself\u001B[39m._response_closed()\n\u001B[32m--> \u001B[39m\u001B[32m136\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m exc\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:106\u001B[39m, in \u001B[36mHTTP11Connection.handle_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m     95\u001B[39m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[32m     97\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m Trace(\n\u001B[32m     98\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mreceive_response_headers\u001B[39m\u001B[33m\"\u001B[39m, logger, request, kwargs\n\u001B[32m     99\u001B[39m ) \u001B[38;5;28;01mas\u001B[39;00m trace:\n\u001B[32m    100\u001B[39m     (\n\u001B[32m    101\u001B[39m         http_version,\n\u001B[32m    102\u001B[39m         status,\n\u001B[32m    103\u001B[39m         reason_phrase,\n\u001B[32m    104\u001B[39m         headers,\n\u001B[32m    105\u001B[39m         trailing_data,\n\u001B[32m--> \u001B[39m\u001B[32m106\u001B[39m     ) = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_receive_response_headers\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    107\u001B[39m     trace.return_value = (\n\u001B[32m    108\u001B[39m         http_version,\n\u001B[32m    109\u001B[39m         status,\n\u001B[32m    110\u001B[39m         reason_phrase,\n\u001B[32m    111\u001B[39m         headers,\n\u001B[32m    112\u001B[39m     )\n\u001B[32m    114\u001B[39m network_stream = \u001B[38;5;28mself\u001B[39m._network_stream\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:177\u001B[39m, in \u001B[36mHTTP11Connection._receive_response_headers\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    174\u001B[39m timeout = timeouts.get(\u001B[33m\"\u001B[39m\u001B[33mread\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m    176\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m177\u001B[39m     event = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_receive_event\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    178\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(event, h11.Response):\n\u001B[32m    179\u001B[39m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:217\u001B[39m, in \u001B[36mHTTP11Connection._receive_event\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    214\u001B[39m     event = \u001B[38;5;28mself\u001B[39m._h11_state.next_event()\n\u001B[32m    216\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m event \u001B[38;5;129;01mis\u001B[39;00m h11.NEED_DATA:\n\u001B[32m--> \u001B[39m\u001B[32m217\u001B[39m     data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_network_stream\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    218\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mREAD_NUM_BYTES\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\n\u001B[32m    219\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    221\u001B[39m     \u001B[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001B[39;00m\n\u001B[32m    222\u001B[39m     \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[32m    223\u001B[39m     \u001B[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    227\u001B[39m     \u001B[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001B[39;00m\n\u001B[32m    228\u001B[39m     \u001B[38;5;66;03m# it as a ConnectError.\u001B[39;00m\n\u001B[32m    229\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m data == \u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/httpcore/_backends/sync.py:128\u001B[39m, in \u001B[36mSyncStream.read\u001B[39m\u001B[34m(self, max_bytes, timeout)\u001B[39m\n\u001B[32m    126\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m map_exceptions(exc_map):\n\u001B[32m    127\u001B[39m     \u001B[38;5;28mself\u001B[39m._sock.settimeout(timeout)\n\u001B[32m--> \u001B[39m\u001B[32m128\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_sock\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrecv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmax_bytes\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9299e8b627ff6ee8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
