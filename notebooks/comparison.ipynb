{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T20:34:09.210161Z",
     "start_time": "2025-10-27T20:33:08.108888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "from src.lexicon_absa import LexiconABSA\n",
    "from src.transformer_absa import TransformerABSA\n",
    "from src.llm_absa import LLMABSA\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ASPECT-BASED SENTIMENT ANALYSIS - THREE APPROACHES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load test samples from JSON\n",
    "with open('../data/test_samples.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "test_texts = [item['text'] for item in test_data]\n",
    "\n",
    "# Initialize all analyzers\n",
    "analyzers = {\n",
    "    'Lexicon': LexiconABSA(),\n",
    "    'Transformer': TransformerABSA(),\n",
    "    'LLM': LLMABSA()\n",
    "}\n",
    "\n",
    "# ==================== QUALITATIVE ANALYSIS FIRST ====================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"QUALITATIVE ANALYSIS - TEXT-BY-TEXT RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Compare results on sample texts\n",
    "for idx, item in enumerate(test_data):\n",
    "    text = item['text']\n",
    "    expected = item['expected']\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Text {idx+1}: {text}\")\n",
    "    print(f\"Expected Aspects & Sentiments:\")\n",
    "    for exp in expected:\n",
    "        print(f\"  - {exp['aspect']}: {exp['sentiment']}\")\n",
    "    print('='*60)\n",
    "\n",
    "    for name, analyzer in analyzers.items():\n",
    "        print(f\"\\n{name} Results:\")\n",
    "        start = time.time()\n",
    "        results = analyzer.analyze(text)\n",
    "        elapsed = time.time() - start\n",
    "\n",
    "        if results:\n",
    "            for r in results:\n",
    "                print(f\"  {r}\")\n",
    "        else:\n",
    "            print(\"  (No aspects detected)\")\n",
    "        print(f\"  Time: {elapsed:.3f}s\")\n",
    "\n",
    "# ==================== PERFORMANCE METRICS USING NEW METHODS ====================\n",
    "print(\"\\n\\n\" + \"=\"*60)\n",
    "print(\"COMPREHENSIVE PERFORMANCE METRICS\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "all_metrics = {}\n",
    "for name, analyzer in analyzers.items():\n",
    "    print(f\"Calculating metrics for {name}...\")\n",
    "    metrics = analyzer.calculate_all_metrics(test_texts)\n",
    "    all_metrics[name] = metrics\n",
    "    analyzer.print_metrics_report(metrics)\n",
    "    print()\n",
    "\n",
    "# ==================== PERFORMANCE COMPARISON TABLE ====================\n",
    "print(\"\\nðŸ“‹ PERFORMANCE COMPARISON TABLE\\n\")\n",
    "\n",
    "comparison_table = []\n",
    "for name, metrics in all_metrics.items():\n",
    "    comparison_table.append({\n",
    "        'Model': name,\n",
    "        'Speed (s/text)': f\"{metrics['speed']['avg_time_per_text']:.4f}\",\n",
    "        'Throughput (texts/s)': f\"{metrics['speed']['throughput_texts_per_second']:.2f}\",\n",
    "        'Aspects Detected': f\"{metrics['aspects_detected']['mean']:.2f}\",\n",
    "        'Avg Confidence': f\"{metrics['avg_confidence']['avg']:.4f}\",\n",
    "        'Memory (MB)': f\"{metrics['memory_usage']['peak_memory_mb']:.4f}\",\n",
    "        'Init Time (s)': f\"{metrics['initialization']['time_seconds']:.4f}\"\n",
    "    })\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_table)\n",
    "print(df_comparison.to_string(index=False))\n",
    "\n",
    "# ==================== DETAILED METRICS VISUALIZATION ====================\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('Performance Metrics Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "methods = list(all_metrics.keys())\n",
    "colors = ['#2ecc71', '#3498db', '#e74c3c']\n",
    "\n",
    "# Plot 1: Speed (avg time per text)\n",
    "speeds = [all_metrics[m]['speed']['avg_time_per_text'] for m in methods]\n",
    "axes[0, 0].bar(methods, speeds, color=colors)\n",
    "axes[0, 0].set_ylabel('Time (seconds)', fontsize=11)\n",
    "axes[0, 0].set_title('Average Time per Text', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_yscale('log')\n",
    "for i, v in enumerate(speeds):\n",
    "    axes[0, 0].text(i, v, f'{v:.4f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Plot 2: Aspects Detected\n",
    "aspects_mean = [all_metrics[m]['aspects_detected']['mean'] for m in methods]\n",
    "aspects_std = [all_metrics[m]['aspects_detected']['std'] for m in methods]\n",
    "axes[0, 1].bar(methods, aspects_mean, yerr=aspects_std, color=colors, capsize=5)\n",
    "axes[0, 1].set_ylabel('Aspects', fontsize=11)\n",
    "axes[0, 1].set_title('Aspects Detected (Mean Â± Std)', fontsize=12, fontweight='bold')\n",
    "for i, v in enumerate(aspects_mean):\n",
    "    axes[0, 1].text(i, v, f'{v:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Plot 3: Average Confidence\n",
    "confidences = [all_metrics[m]['avg_confidence']['avg'] for m in methods]\n",
    "axes[0, 2].bar(methods, confidences, color=colors)\n",
    "axes[0, 2].set_ylabel('Confidence', fontsize=11)\n",
    "axes[0, 2].set_title('Average Confidence Score', fontsize=12, fontweight='bold')\n",
    "axes[0, 2].set_ylim([0, 1.0])\n",
    "for i, v in enumerate(confidences):\n",
    "    axes[0, 2].text(i, v, f'{v:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Plot 4: Memory Usage\n",
    "memory = [all_metrics[m]['memory_usage']['peak_memory_mb'] for m in methods]\n",
    "axes[1, 0].bar(methods, memory, color=colors)\n",
    "axes[1, 0].set_ylabel('Memory (MB)', fontsize=11)\n",
    "axes[1, 0].set_title('Peak Memory Usage', fontsize=12, fontweight='bold')\n",
    "for i, v in enumerate(memory):\n",
    "    axes[1, 0].text(i, v, f'{v:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Plot 5: Initialization Time\n",
    "init_times = [all_metrics[m]['initialization']['time_seconds'] for m in methods]\n",
    "axes[1, 1].bar(methods, init_times, color=colors)\n",
    "axes[1, 1].set_ylabel('Time (seconds)', fontsize=11)\n",
    "axes[1, 1].set_title('Initialization Time', fontsize=12, fontweight='bold')\n",
    "for i, v in enumerate(init_times):\n",
    "    axes[1, 1].text(i, v, f'{v:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Plot 6: Throughput\n",
    "throughput = [all_metrics[m]['speed']['throughput_texts_per_second'] for m in methods]\n",
    "axes[1, 2].bar(methods, throughput, color=colors)\n",
    "axes[1, 2].set_ylabel('Texts/Second', fontsize=11)\n",
    "axes[1, 2].set_title('Processing Throughput', fontsize=12, fontweight='bold')\n",
    "for i, v in enumerate(throughput):\n",
    "    axes[1, 2].text(i, v, f'{v:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('performance_metrics_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# ==================== ORIGINAL QUALITATIVE ANALYSIS ====================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"QUALITATIVE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Compare results on sample texts\n",
    "for idx, item in enumerate(test_data[:3]):  # Show first 3 texts\n",
    "    text = item['text']\n",
    "    expected = item['expected']\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Text {idx+1}: {text}\")\n",
    "    print(f\"Expected: {expected}\")\n",
    "    print('='*60)\n",
    "\n",
    "    for name, analyzer in analyzers.items():\n",
    "        print(f\"\\n{name} Results:\")\n",
    "        start = time.time()\n",
    "        results = analyzer.analyze(text)\n",
    "        elapsed = time.time() - start\n",
    "\n",
    "        for r in results:\n",
    "            print(f\"  {r}\")\n",
    "        print(f\"  Time: {elapsed:.3f}s\")\n",
    "\n",
    "# === ACCURACY EVALUATION ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ACCURACY EVALUATION\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "accuracy_data = []\n",
    "for item in test_data:\n",
    "    text = item['text']\n",
    "    expected = item['expected']\n",
    "    expected_aspects = {e['aspect'].lower() for e in expected}\n",
    "    expected_sentiments = {e['aspect'].lower(): e['sentiment'] for e in expected}\n",
    "\n",
    "    for name, analyzer in analyzers.items():\n",
    "        results = analyzer.analyze(text)\n",
    "        detected_aspects = {r.aspect.lower() for r in results}\n",
    "\n",
    "        # Calculate metrics\n",
    "        correct_aspects = len(expected_aspects & detected_aspects)\n",
    "        precision = correct_aspects / len(detected_aspects) if detected_aspects else 0\n",
    "        recall = correct_aspects / len(expected_aspects) if expected_aspects else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "        # Check sentiment accuracy\n",
    "        sentiment_correct = 0\n",
    "        for r in results:\n",
    "            aspect_lower = r.aspect.lower()\n",
    "            if aspect_lower in expected_sentiments:\n",
    "                if r.sentiment == expected_sentiments[aspect_lower]:\n",
    "                    sentiment_correct += 1\n",
    "\n",
    "        sentiment_accuracy = sentiment_correct / len(expected) if expected else 0\n",
    "\n",
    "        accuracy_data.append({\n",
    "            'Method': name,\n",
    "            'Text': text[:30] + '...',\n",
    "            'Precision': f\"{precision:.2f}\",\n",
    "            'Recall': f\"{recall:.2f}\",\n",
    "            'F1': f\"{f1:.2f}\",\n",
    "            'Sentiment_Acc': f\"{sentiment_accuracy:.2f}\"\n",
    "        })\n",
    "\n",
    "df_accuracy = pd.DataFrame(accuracy_data)\n",
    "print(df_accuracy.to_string(index=False))\n",
    "\n",
    "# Aggregate accuracy by method\n",
    "print(\"\\nðŸ“Š AVERAGE ACCURACY BY METHOD\\n\")\n",
    "avg_accuracy = df_accuracy.groupby('Method').agg({\n",
    "    'Precision': lambda x: f\"{np.mean([float(v) for v in x]):.2f}\",\n",
    "    'Recall': lambda x: f\"{np.mean([float(v) for v in x]):.2f}\",\n",
    "    'F1': lambda x: f\"{np.mean([float(v) for v in x]):.2f}\",\n",
    "    'Sentiment_Acc': lambda x: f\"{np.mean([float(v) for v in x]):.2f}\"\n",
    "}).reset_index()\n",
    "print(avg_accuracy.to_string(index=False))\n",
    "\n",
    "# === DETAILED COMPARISON - TEXT 1 ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DETAILED COMPARISON - TEXT 1\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "text = test_data[0]['text']\n",
    "expected = test_data[0]['expected']\n",
    "print(f\"Text: '{text}'\")\n",
    "print(f\"Expected: {expected}\\n\")\n",
    "\n",
    "comparison_results = []\n",
    "for name, analyzer in analyzers.items():\n",
    "    results = analyzer.analyze(text)\n",
    "    for r in results:\n",
    "        comparison_results.append({\n",
    "            'Method': name,\n",
    "            'Aspect': r.aspect,\n",
    "            'Sentiment': r.sentiment,\n",
    "            'Confidence': f\"{r.confidence:.2f}\"\n",
    "        })\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_results)\n",
    "print(df_comparison.to_string(index=False))\n",
    "\n",
    "# === EDGE CASES ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EDGE CASES\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "for text, label in [(\"wasn't bad\", \"Negation\"), (\"okay\", \"Neutral\"), (\"\", \"Empty\")]:\n",
    "    print(f\"{label}: '{text}'\")\n",
    "    for name, analyzer in analyzers.items():\n",
    "        try:\n",
    "            r = analyzer.analyze(text)\n",
    "            print(f\"  {name}: {len(r)} aspects - {[res.sentiment for res in r]}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  {name}: ERROR - {str(e)}\")\n",
    "    print()\n",
    "\n",
    "# === FINAL SUMMARY ===\n",
    "print(\"=\"*60)\n",
    "print(\"SUMMARY & RECOMMENDATIONS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nðŸŽ¯ BEST FOR:\")\n",
    "print(f\"  â€¢ Speed: {min(methods, key=lambda m: all_metrics[m]['speed']['avg_time_per_text'])}\")\n",
    "print(f\"  â€¢ Accuracy: {max(methods, key=lambda m: all_metrics[m]['avg_confidence']['avg'])}\")\n",
    "print(f\"  â€¢ Memory Efficiency: {min(methods, key=lambda m: all_metrics[m]['memory_usage']['peak_memory_mb'])}\")\n",
    "print(f\"  â€¢ Throughput: {max(methods, key=lambda m: all_metrics[m]['speed']['throughput_texts_per_second'])}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ USE CASES:\")\n",
    "print(\"  â€¢ Real-time API â†’ Lexicon (fastest)\")\n",
    "print(\"  â€¢ Production App â†’ Transformer (balanced)\")\n",
    "print(\"  â€¢ Research/Analysis â†’ LLM (most detailed)\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ],
   "id": "438d7d13be19ca8a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ASPECT-BASED SENTIMENT ANALYSIS - THREE APPROACHES\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "QUALITATIVE ANALYSIS - TEXT-BY-TEXT RESULTS\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Text 1: All I can say is they have very good ice cream I would for sure recommend their cookies and creme ice cream it is very good\n",
      "Expected Aspects & Sentiments:\n",
      "  - ice cream: positive\n",
      "  - cookies and creme ice cream: positive\n",
      "============================================================\n",
      "\n",
      "Lexicon Results:\n",
      "DEBUG: Found 1 aspects: ['creme ice cream']\n",
      "  Aspect: 'creme ice cream' â†’ Sentiment: POSITIVE (confidence: 0.79)\n",
      "  Time: 0.020s\n",
      "\n",
      "Transformer Results:\n",
      "  Aspect: 'creme ice cream' â†’ Sentiment: POSITIVE (confidence: 1.00)\n",
      "  Time: 0.190s\n",
      "\n",
      "LLM Results:\n",
      "  Aspect: 'ice cream' â†’ Sentiment: POSITIVE (confidence: 0.95)\n",
      "  Aspect: 'cookies and creme ice cream' â†’ Sentiment: POSITIVE (confidence: 0.90)\n",
      "  Time: 36.797s\n",
      "\n",
      "============================================================\n",
      "Text 2: Nice little local place for ice cream.My favorite is their pumpkin shake, Fall season special. My Sweetness tolerance is low. Their LARGE SIZE ice cream usually seems too sweet after having ice cream for a while. But love their pina colada. So refreshing. Their Banana Split is good too.\n",
      "Expected Aspects & Sentiments:\n",
      "  - place: positive\n",
      "  - pumpkin shake: positive\n",
      "  - large size ice cream: negative\n",
      "  - pina colada: positive\n",
      "  - banana split: positive\n",
      "============================================================\n",
      "\n",
      "Lexicon Results:\n",
      "DEBUG: Found 6 aspects: ['little local place', 'ice cream', 'pumpkin shake', 'size ice cream', 'pina colada', 'banana split']\n",
      "  Aspect: 'little local place' â†’ Sentiment: POSITIVE (confidence: 0.42)\n",
      "  Aspect: 'ice cream' â†’ Sentiment: POSITIVE (confidence: 0.42)\n",
      "  Aspect: 'pumpkin shake' â†’ Sentiment: NEGATIVE (confidence: 0.18)\n",
      "  Aspect: 'size ice cream' â†’ Sentiment: NEUTRAL (confidence: 0.00)\n",
      "  Aspect: 'pina colada' â†’ Sentiment: NEUTRAL (confidence: 0.00)\n",
      "  Aspect: 'banana split' â†’ Sentiment: POSITIVE (confidence: 0.44)\n",
      "  Time: 0.026s\n",
      "\n",
      "Transformer Results:\n",
      "  Aspect: 'little local place' â†’ Sentiment: POSITIVE (confidence: 0.99)\n",
      "  Aspect: 'ice cream' â†’ Sentiment: POSITIVE (confidence: 0.73)\n",
      "  Aspect: 'pumpkin shake' â†’ Sentiment: POSITIVE (confidence: 0.99)\n",
      "  Aspect: 'size ice cream' â†’ Sentiment: NEUTRAL (confidence: 0.46)\n",
      "  Aspect: 'pina colada' â†’ Sentiment: POSITIVE (confidence: 0.99)\n",
      "  Aspect: 'banana split' â†’ Sentiment: POSITIVE (confidence: 0.99)\n",
      "  Time: 1.645s\n",
      "\n",
      "LLM Results:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 50\u001B[39m\n\u001B[32m     48\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m Results:\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     49\u001B[39m start = time.time()\n\u001B[32m---> \u001B[39m\u001B[32m50\u001B[39m results = \u001B[43manalyzer\u001B[49m\u001B[43m.\u001B[49m\u001B[43manalyze\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     51\u001B[39m elapsed = time.time() - start\n\u001B[32m     53\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m results:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/src/llm_absa.py:17\u001B[39m, in \u001B[36mLLMABSA.analyze\u001B[39m\u001B[34m(self, text)\u001B[39m\n\u001B[32m     14\u001B[39m prompt = \u001B[38;5;28mself\u001B[39m._create_prompt(text)\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m     response = \u001B[43mollama\u001B[49m\u001B[43m.\u001B[49m\u001B[43mchat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     18\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     19\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mrole\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43muser\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mcontent\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m}\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     20\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mjson\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Request JSON output\u001B[39;49;00m\n\u001B[32m     21\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     23\u001B[39m     result = json.loads(response[\u001B[33m'\u001B[39m\u001B[33mmessage\u001B[39m\u001B[33m'\u001B[39m][\u001B[33m'\u001B[39m\u001B[33mcontent\u001B[39m\u001B[33m'\u001B[39m])\n\u001B[32m     24\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._parse_response(result)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/ollama/_client.py:351\u001B[39m, in \u001B[36mClient.chat\u001B[39m\u001B[34m(self, model, messages, tools, stream, think, format, options, keep_alive)\u001B[39m\n\u001B[32m    306\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mchat\u001B[39m(\n\u001B[32m    307\u001B[39m   \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    308\u001B[39m   model: \u001B[38;5;28mstr\u001B[39m = \u001B[33m'\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    316\u001B[39m   keep_alive: Optional[Union[\u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28mstr\u001B[39m]] = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    317\u001B[39m ) -> Union[ChatResponse, Iterator[ChatResponse]]:\n\u001B[32m    318\u001B[39m \u001B[38;5;250m  \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    319\u001B[39m \u001B[33;03m  Create a chat response using the requested model.\u001B[39;00m\n\u001B[32m    320\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    349\u001B[39m \u001B[33;03m  Returns `ChatResponse` if `stream` is `False`, otherwise returns a `ChatResponse` generator.\u001B[39;00m\n\u001B[32m    350\u001B[39m \u001B[33;03m  \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m351\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    352\u001B[39m \u001B[43m    \u001B[49m\u001B[43mChatResponse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    353\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mPOST\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    354\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43m/api/chat\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[43m    \u001B[49m\u001B[43mjson\u001B[49m\u001B[43m=\u001B[49m\u001B[43mChatRequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    356\u001B[39m \u001B[43m      \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    357\u001B[39m \u001B[43m      \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m_copy_messages\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    358\u001B[39m \u001B[43m      \u001B[49m\u001B[43mtools\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m_copy_tools\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtools\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    359\u001B[39m \u001B[43m      \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    360\u001B[39m \u001B[43m      \u001B[49m\u001B[43mthink\u001B[49m\u001B[43m=\u001B[49m\u001B[43mthink\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    361\u001B[39m \u001B[43m      \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    362\u001B[39m \u001B[43m      \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    363\u001B[39m \u001B[43m      \u001B[49m\u001B[43mkeep_alive\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkeep_alive\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    364\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmodel_dump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexclude_none\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    365\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    366\u001B[39m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/ollama/_client.py:189\u001B[39m, in \u001B[36mClient._request\u001B[39m\u001B[34m(self, cls, stream, *args, **kwargs)\u001B[39m\n\u001B[32m    185\u001B[39m         \u001B[38;5;28;01myield\u001B[39;00m \u001B[38;5;28mcls\u001B[39m(**part)\n\u001B[32m    187\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m inner()\n\u001B[32m--> \u001B[39m\u001B[32m189\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m(**\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_request_raw\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m.json())\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/ollama/_client.py:129\u001B[39m, in \u001B[36mClient._request_raw\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    127\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_request_raw\u001B[39m(\u001B[38;5;28mself\u001B[39m, *args, **kwargs):\n\u001B[32m    128\u001B[39m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m129\u001B[39m     r = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_client\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    130\u001B[39m     r.raise_for_status()\n\u001B[32m    131\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m r\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/httpx/_client.py:825\u001B[39m, in \u001B[36mClient.request\u001B[39m\u001B[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001B[39m\n\u001B[32m    810\u001B[39m     warnings.warn(message, \u001B[38;5;167;01mDeprecationWarning\u001B[39;00m, stacklevel=\u001B[32m2\u001B[39m)\n\u001B[32m    812\u001B[39m request = \u001B[38;5;28mself\u001B[39m.build_request(\n\u001B[32m    813\u001B[39m     method=method,\n\u001B[32m    814\u001B[39m     url=url,\n\u001B[32m   (...)\u001B[39m\u001B[32m    823\u001B[39m     extensions=extensions,\n\u001B[32m    824\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m825\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mauth\u001B[49m\u001B[43m=\u001B[49m\u001B[43mauth\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/httpx/_client.py:914\u001B[39m, in \u001B[36mClient.send\u001B[39m\u001B[34m(self, request, stream, auth, follow_redirects)\u001B[39m\n\u001B[32m    910\u001B[39m \u001B[38;5;28mself\u001B[39m._set_timeout(request)\n\u001B[32m    912\u001B[39m auth = \u001B[38;5;28mself\u001B[39m._build_request_auth(request, auth)\n\u001B[32m--> \u001B[39m\u001B[32m914\u001B[39m response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_send_handling_auth\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    915\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    916\u001B[39m \u001B[43m    \u001B[49m\u001B[43mauth\u001B[49m\u001B[43m=\u001B[49m\u001B[43mauth\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    917\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    918\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhistory\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    919\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    920\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    921\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m stream:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/httpx/_client.py:942\u001B[39m, in \u001B[36mClient._send_handling_auth\u001B[39m\u001B[34m(self, request, auth, follow_redirects, history)\u001B[39m\n\u001B[32m    939\u001B[39m request = \u001B[38;5;28mnext\u001B[39m(auth_flow)\n\u001B[32m    941\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m942\u001B[39m     response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_send_handling_redirects\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    943\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    944\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfollow_redirects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    945\u001B[39m \u001B[43m        \u001B[49m\u001B[43mhistory\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhistory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    946\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    947\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    948\u001B[39m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/httpx/_client.py:979\u001B[39m, in \u001B[36mClient._send_handling_redirects\u001B[39m\u001B[34m(self, request, follow_redirects, history)\u001B[39m\n\u001B[32m    976\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._event_hooks[\u001B[33m\"\u001B[39m\u001B[33mrequest\u001B[39m\u001B[33m\"\u001B[39m]:\n\u001B[32m    977\u001B[39m     hook(request)\n\u001B[32m--> \u001B[39m\u001B[32m979\u001B[39m response = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_send_single_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    980\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    981\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._event_hooks[\u001B[33m\"\u001B[39m\u001B[33mresponse\u001B[39m\u001B[33m\"\u001B[39m]:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/httpx/_client.py:1014\u001B[39m, in \u001B[36mClient._send_single_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m   1009\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[32m   1010\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mAttempted to send an async request with a sync Client instance.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1011\u001B[39m     )\n\u001B[32m   1013\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request=request):\n\u001B[32m-> \u001B[39m\u001B[32m1014\u001B[39m     response = \u001B[43mtransport\u001B[49m\u001B[43m.\u001B[49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1016\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response.stream, SyncByteStream)\n\u001B[32m   1018\u001B[39m response.request = request\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:250\u001B[39m, in \u001B[36mHTTPTransport.handle_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    237\u001B[39m req = httpcore.Request(\n\u001B[32m    238\u001B[39m     method=request.method,\n\u001B[32m    239\u001B[39m     url=httpcore.URL(\n\u001B[32m   (...)\u001B[39m\u001B[32m    247\u001B[39m     extensions=request.extensions,\n\u001B[32m    248\u001B[39m )\n\u001B[32m    249\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m map_httpcore_exceptions():\n\u001B[32m--> \u001B[39m\u001B[32m250\u001B[39m     resp = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_pool\u001B[49m\u001B[43m.\u001B[49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreq\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    252\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(resp.stream, typing.Iterable)\n\u001B[32m    254\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m Response(\n\u001B[32m    255\u001B[39m     status_code=resp.status,\n\u001B[32m    256\u001B[39m     headers=resp.headers,\n\u001B[32m    257\u001B[39m     stream=ResponseStream(resp.stream),\n\u001B[32m    258\u001B[39m     extensions=resp.extensions,\n\u001B[32m    259\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001B[39m, in \u001B[36mConnectionPool.handle_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    253\u001B[39m         closing = \u001B[38;5;28mself\u001B[39m._assign_requests_to_connections()\n\u001B[32m    255\u001B[39m     \u001B[38;5;28mself\u001B[39m._close_connections(closing)\n\u001B[32m--> \u001B[39m\u001B[32m256\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m exc \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    258\u001B[39m \u001B[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001B[39;00m\n\u001B[32m    259\u001B[39m \u001B[38;5;66;03m# the point at which the response is closed.\u001B[39;00m\n\u001B[32m    260\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response.stream, typing.Iterable)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001B[39m, in \u001B[36mConnectionPool.handle_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    232\u001B[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001B[32m    234\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    235\u001B[39m     \u001B[38;5;66;03m# Send the request on the assigned connection.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m236\u001B[39m     response = \u001B[43mconnection\u001B[49m\u001B[43m.\u001B[49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    237\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpool_request\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrequest\u001B[49m\n\u001B[32m    238\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    239\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m ConnectionNotAvailable:\n\u001B[32m    240\u001B[39m     \u001B[38;5;66;03m# In some cases a connection may initially be available to\u001B[39;00m\n\u001B[32m    241\u001B[39m     \u001B[38;5;66;03m# handle a request, but then become unavailable.\u001B[39;00m\n\u001B[32m    242\u001B[39m     \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[32m    243\u001B[39m     \u001B[38;5;66;03m# In this case we clear the connection and try again.\u001B[39;00m\n\u001B[32m    244\u001B[39m     pool_request.clear_connection()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:103\u001B[39m, in \u001B[36mHTTPConnection.handle_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    100\u001B[39m     \u001B[38;5;28mself\u001B[39m._connect_failed = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m    101\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m exc\n\u001B[32m--> \u001B[39m\u001B[32m103\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_connection\u001B[49m\u001B[43m.\u001B[49m\u001B[43mhandle_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:136\u001B[39m, in \u001B[36mHTTP11Connection.handle_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    134\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m Trace(\u001B[33m\"\u001B[39m\u001B[33mresponse_closed\u001B[39m\u001B[33m\"\u001B[39m, logger, request) \u001B[38;5;28;01mas\u001B[39;00m trace:\n\u001B[32m    135\u001B[39m         \u001B[38;5;28mself\u001B[39m._response_closed()\n\u001B[32m--> \u001B[39m\u001B[32m136\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m exc\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:106\u001B[39m, in \u001B[36mHTTP11Connection.handle_request\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m     95\u001B[39m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[32m     97\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m Trace(\n\u001B[32m     98\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mreceive_response_headers\u001B[39m\u001B[33m\"\u001B[39m, logger, request, kwargs\n\u001B[32m     99\u001B[39m ) \u001B[38;5;28;01mas\u001B[39;00m trace:\n\u001B[32m    100\u001B[39m     (\n\u001B[32m    101\u001B[39m         http_version,\n\u001B[32m    102\u001B[39m         status,\n\u001B[32m    103\u001B[39m         reason_phrase,\n\u001B[32m    104\u001B[39m         headers,\n\u001B[32m    105\u001B[39m         trailing_data,\n\u001B[32m--> \u001B[39m\u001B[32m106\u001B[39m     ) = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_receive_response_headers\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    107\u001B[39m     trace.return_value = (\n\u001B[32m    108\u001B[39m         http_version,\n\u001B[32m    109\u001B[39m         status,\n\u001B[32m    110\u001B[39m         reason_phrase,\n\u001B[32m    111\u001B[39m         headers,\n\u001B[32m    112\u001B[39m     )\n\u001B[32m    114\u001B[39m network_stream = \u001B[38;5;28mself\u001B[39m._network_stream\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:177\u001B[39m, in \u001B[36mHTTP11Connection._receive_response_headers\u001B[39m\u001B[34m(self, request)\u001B[39m\n\u001B[32m    174\u001B[39m timeout = timeouts.get(\u001B[33m\"\u001B[39m\u001B[33mread\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m    176\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m177\u001B[39m     event = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_receive_event\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    178\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(event, h11.Response):\n\u001B[32m    179\u001B[39m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:217\u001B[39m, in \u001B[36mHTTP11Connection._receive_event\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    214\u001B[39m     event = \u001B[38;5;28mself\u001B[39m._h11_state.next_event()\n\u001B[32m    216\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m event \u001B[38;5;129;01mis\u001B[39;00m h11.NEED_DATA:\n\u001B[32m--> \u001B[39m\u001B[32m217\u001B[39m     data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_network_stream\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    218\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mREAD_NUM_BYTES\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\n\u001B[32m    219\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    221\u001B[39m     \u001B[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001B[39;00m\n\u001B[32m    222\u001B[39m     \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[32m    223\u001B[39m     \u001B[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    227\u001B[39m     \u001B[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001B[39;00m\n\u001B[32m    228\u001B[39m     \u001B[38;5;66;03m# it as a ConnectError.\u001B[39;00m\n\u001B[32m    229\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m data == \u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/study/da6/LLM-MLOps-Portfolio/Sentiment-Analysis-Project/.venv/lib/python3.12/site-packages/httpcore/_backends/sync.py:128\u001B[39m, in \u001B[36mSyncStream.read\u001B[39m\u001B[34m(self, max_bytes, timeout)\u001B[39m\n\u001B[32m    126\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m map_exceptions(exc_map):\n\u001B[32m    127\u001B[39m     \u001B[38;5;28mself\u001B[39m._sock.settimeout(timeout)\n\u001B[32m--> \u001B[39m\u001B[32m128\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_sock\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrecv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmax_bytes\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f1af4e5f53e55703"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
